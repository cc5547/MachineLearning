{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chohoon901/MachineLearning/blob/main/sunghuncho/CH08_05%2B06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 결정 트리 (Decision Tree, 의사결정)\n",
        "* 트리 cf) 그래프 (자료구조)\n",
        "    * 한 방향으로 전개되는 데이터 구조\n",
        "    * 뿌리(root)에서 잎(leaf)로 뻗어가면서 데이터가 갈라지는 구조\n",
        "    * 뿌리 하나에 가지(잎)이 2개 -> 이진 트리\n",
        "* 결정 트리 -> 이진 트리 -> 기준점(지니 계수 -> 특정한 변수의 값을 기준을 나누었을 때 결과값이 얼마나 순수하게 나뉘냐) (0, 1) => 특정 변수로 나누면... (0 그룹) (1그룹)으로 안 나뉘어짐\n",
        "    * 키 기준으로 남/녀를 나누었을 때랑, 운동화를 신었냐 기준으로 남녀를 나뉘었을 때? 어디가 좀 더 깔끔하게 남/녀 구분?\n",
        "* 전제가 없음\n",
        "    * 데이터의 선형성, 독립변수들 간의 다중공산성(상관성), 데이터의 이상치 여부, 데이터 단위 -> 신경써주지 않아도 됨\n",
        "    * 나눠지는 기준값을 기준으로 그룹을 나눠서 대응 -> 선형을 이루던가, 거리를 재던가 하지 않음, 그냥 반반 혹은 의미는 규모의 그룹으로 나누기\n",
        "    * 딥러닝을 제외한 머신러닝 쪽에서 가장 높은 예측력을 보이는 알고리즘 계열 -> 점점 고도화됨 -> 가장 기초적인 결정 트리 -> 경사하강법, 앙상블, 배깅, 부스팅 같은 기타 추가적인 기법들을 도입한 고도화된 트리 모델\n",
        "* 종속변수가 이산형이든 연속형이든 상관 없음, 분류문제/회귀문제 모두 대응 가능 (`classifier, regressor`)\n",
        "* 이걸 이해해야 뒤에 나오는 고도화된 트리 모델들의 기초 원리가 이해 가능\n",
        "* 가장 단순한 트리 모델이기 때문에, 시각화나 설명이 간단 (`plot_tree`)\n",
        "    * 예측력 (결과, 평가, 점수) vs 설명력 (시각화, 원인, 영향도) -> 자율주행, 내비게이션"
      ],
      "metadata": {
        "id": "yNBKrynY7Vul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 범주형 변수의 변환 -> 피쳐 엔지니어링적 성격\n",
        "* 순서형 : 크고 작음이 있다 -> A+ > B+ (학점), AAA > BBB (신용등급)\n",
        "    * 트리 계열 -> 라벨 인코딩 -> n개를 그냥 1~n까지로 인코딩해도 됨\n",
        "    * 범주형 변수 -> 거기에 대응하는 대표적인 값을 넣어서 순서형\n",
        "        * 나라 -> 나라별 고소득자 비율, 브랜드 -> 브랜드 평판, 해당 기업의 시가총액\n",
        "        * 이렇게 변환해줄 경우에는 가능하면 안 겹치는 값\n",
        "        * 대표값을 잘못 적용해주면? 이상한 모델링\n",
        "* 명목형 : 위아래가 없음. 소속. 특성. 상태.\n",
        "    * 더미변수로 해줌\n",
        "---\n",
        "* 더미변수화를 하면, 해당 범주 종류(고윳값)의 n-1개의 행이 생김. (n-2개로 늘어남) -> 열이 늘어난 건, 행당 처리해야하는 데이터가 늘어남 -> 빅데이터(몇만, 몇십백만...) 배수로 늘어남 -> 100개의 종류가 있는 데이터 -> 더미변수화? -> 모델 학습 효율 떨어짐 -> 모델 성능의 문제, 효율"
      ],
      "metadata": {
        "id": "q1JWcTGsDUJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 결정트리의 하이퍼 패러미터 튜닝\n",
        "* max_depth : 최대 노드의 깊이\n",
        "  * 'from sklearn.tree import Decision...' -> default? : 확실히 두 그룹으로 나뉠때 까지\n",
        "  * 과최적화 : 훈련셋 데이터에 최적화되있어 시험셋을 만났을때 제대로 분류를 못함\n",
        "  * 과소학습 : 학습이 제데로 안됨\n",
        "  * 일정 이상으로 노드 전개를 막아서 세세한 조건을 주지 않게 함.\n",
        "  "
      ],
      "metadata": {
        "id": "CIz061eMDZ6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 랜덤 포레스트 (Random Forest)\n",
        "* 결정트리 -> 과최적화 -> 앙상블 -> 여러 모델들을 통합시켜서 더 좋은 예측력을 보일 수 있게 하는 모델\n",
        "* 트리 -> 포레스트 -> 트리를 여러개 생성하고, 결과값들을 투표(분류 -> 모델1: 0,모델2: 0,모델3: 1 -> 0)나 평균화 시켜서 예측력을 높임\n",
        "* 속도가 좀 느려진다(모델 여러개 만들어서)는 것을 제외하곤 결정트리하고 유사-> 여러개를 섞어서 시각화X"
      ],
      "metadata": {
        "id": "jD-402kWF244"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단위 처리 & 도메인 지식을 이용한 전처리(피쳐 엔지니어링)\n",
        "* cc,kg,N -> 숫자를 주어지는게 아니라 단위와 함께 주어지는 경우가 많음\n",
        "1. 값과 단위를 분리(value,int)->'series.split()','series.str.split(expand=True)','series.str.extract(정규표현식)','series.apply(함수)'\n",
        "2. 단위가 한가지 인가?\n",
        "  1. 단위가 한가지 이면(cc,m 등으로 통일?) -> 그 값 자체를 써주면 됨\n",
        "  2. 2개 이상이면?\n",
        "    * 한쪽 값으로 통일\n",
        "    * 가격, 점수, 석차, 비율 등.. 공통된 단위로 통일\n",
        "    * 도메인 지식 -> 특정 영역에 대해 갖고 있는 상식, 기술적 지식"
      ],
      "metadata": {
        "id": "Kpe-n2BbGsJP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 랜덤 포레스트의 하이퍼 패러미터 튜닝\n",
        "* 트리 기반에서 하이퍼 패러미터 튜닝은 주\n",
        "* max_depth\n",
        "* `min_samples_split` : 노드를 분할하기 위한 최소 샘플 수를 지정하는 매개변수입니다. 이 매개변수는 노드를 분할할 때, 해당 노드의 샘플 수가 min_samples_split보다 작아지면 분할을 멈추도록 합니다. 즉, 노드를 분할할 때 적어도 min_samples_split개 이상의 샘플이 있어야만 분할이 가능합니다. 이 값을 너무 낮게 설정하면 모델이 과적합(Overfitting)되기 쉽고, 너무 높게 설정하면 모델이 너무 단순해져서 과소적합(Underfitting)될 가능성이 높아집니다.\n",
        "* `min_samples_leaf` : 리프 노드가 되기 위한 최소 샘플 수를 지정하는 매개변수입니다. 이 매개변수는 리프 노드가 될 수 있는 샘플 수가 min_samples_leaf보다 작아지면 노드 분할을 멈추도록 합니다. 즉, 리프 노드가 될 수 있는 샘플 수가 min_samples_leaf보다 적다면 해당 노드는 분할을 멈추고 리프 노드가 됩니다. 이 값을 너무 낮게 설정하면 모델이 과적합되기 쉽고, 너무 높게 설정하면 모델이 너무 단순해져서 과소적합될 가능성이 높아집니다.\n",
        "\n",
        "차이점은 min_samples_split은 노드를 분할할 때 고려해야 할 최소 샘플 수를 설정하는 것이고, min_samples_leaf는 리프 노드가 되기 위한 최소 샘플 수를 설정하는 것입니다. min_samples_split은 노드 분할에 직접적으로 영향을 주며, min_samples_leaf는 리프 노드가 되기 위한 샘플 수를 조절하여 모델의 복잡도를 조절합니다. 따라서 두 매개변수 모두 모델의 복잡도를 조절하여 과적합과 과소적합을 방지하는 데 중요한 역할을 합니다."
      ],
      "metadata": {
        "id": "Dc0NlIZjK1mJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JyYWA4-bK1TR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}