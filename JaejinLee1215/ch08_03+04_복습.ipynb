{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaejinLee1215/MachineLearning/blob/main/JaejinLee1215/ch08_03%2B04_%EB%B3%B5%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN (K-Nearest Neighbor)\n"
      ],
      "metadata": {
        "id": "QXd3csRYqIBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 거리 기반 -> 열들(관측값, 독립변수, 피쳐) 거리를 재서, 그 거리들 간의 계산을 통해, 특정한 정답값(종속변수, 예측값, 라벨)들이 뭉쳐있는지를 확인하고, 해당 정답값들과 얼마나 가까운지를 바탕으로 새로운 예측값\n",
        "\n",
        "* 선형 관계 성립 X <-> 선형회귀(회귀), 로지스틱회귀(분류) => 선형관계\n",
        "  * 선형 관계 : x => 증감함에 따라 y라는 값이 일관적이게 증가, 감소하는 관계 (비례/반비례) => 일관된 직선으로 (독립변수들) - (종속변수) 간의 관계까 나타나는 것 (수학 공식 => 1차식)\n",
        "\n",
        "* 단위 문제 -> 단위가 정리가 안되면, 특정한 변수의 단위 크기에 따른 영향이 극대화 혹은 극소화\n",
        "  * 스케일링\n",
        "* 이상치 (일반적 통계적으로 예측되는 최대/최소값, 상관관계에 벗어나는 값들) \n",
        "  * Ex) 엄마 아빠 키가 180cm 인데 자녀가 150~160cm 일때\n",
        "\n",
        "* 분류(Classifier)/회귀(Regressor) 사용\n",
        "* 로지스틱 회귀 (분류) -> 이진분류 (0,1 Ture, False)\n",
        "* KNN -> 다중분류 (2개부터 n개까지)\n",
        "\n",
        "* 열이나 데이터가 늘어나면 속도가 느려짐(거리 기반이기 때문에)\n",
        "* K라는게 'K'개를 선택해야한다는 의미가 통상적 -> 적절한 K를 선택해줘야함"
      ],
      "metadata": {
        "id": "o7jAonArqPYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 스케일링\n"
      ],
      "metadata": {
        "id": "xjuVC8CZtHLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 단위(Scale)가 중요한 경우 (거리 기반) -> 단위를 맞춰주기 위해서 통계적인 변환을 시켜주는 전처리 (Scaling)\n",
        "\n",
        "* 표준화 스케일링\n",
        "  * 표준정규분포로 만들어주는 스케일링\n",
        "  * 표준정규분포 -> 평균이 0이고, 표준편차가 1인 정규분포 -> 정규분포 : 자연적으로 발생하는 일반적인 확률분포 (종 모양 분포) -> **전체 값에서 평균을 빼고 표준편차로 나눠주면** -> 평균이 0이고 표준편차 1\n",
        "  * 일반적으로 통계에 쓰이는 비교를 위한 표준\n",
        "  * 원본의 모양을 포기하고, 대신에 다양한 변수들 간의 비교를 위해\n",
        "  * 이상치 영향 여부 : 0 (이상치가 발생하면 평균에 영향을 준다.)\n",
        "  * 분포 모양 변화 : 0\n",
        "\n",
        "* 로버스트 스케일링 (Robust)\n",
        "  * 1사분위, 2사분위, 3사분위수를 사용하여 양극단의 이상치에 대한 영향을 최소화한 '굳건한' 스케일링\n",
        "  * (모든 값 2사분위수(중위값, 중간값)) / (3사분위수 - 1사분위수)\n",
        "  * '평균'을 안쓴다 -> 양극단 이상치 영향이 없어짐\n",
        "  * 스케일링시 분포 모양이 양방향으로 퍼져보임 -> (1분위 ~ 3분위 값들은 잘 스케일링, 나머지 값들은 버려지는 경향 - 오해의 소지가 있음)\n",
        "  * 이상치 영향 여부 : X\n",
        "  * 분포 모양 변화 : 1~3사분위는 비슷, 양극단의 값들은 자유분방\n",
        "\n",
        "* 최대 최소 스케일링\n",
        "  * 최대값과 최소값을 사용해서 단위만 0~1 사이로 만듦\n",
        "  * (모든 값 - 최소 값) / (최대값 - 최소값)\n",
        "  * 최소값은 0, 최대값 1인 분포\n",
        "  * 모양 보정은 비교적 수월, 이상치는 그대로\n",
        "  * 이상치 영향 여부 : 0\n",
        "  * 분포 모양 변화 : X - 단위의 문제여서 회전한 것 처럼 보여짐\n",
        "\n",
        "* sklearn.preprocessing"
      ],
      "metadata": {
        "id": "O2uy6qpdtLEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 나이브 베이즈"
      ],
      "metadata": {
        "id": "g3RXggTZxcjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 베이즈 정리 (조건부 확률을 기반한) 알고리즘\n",
        "* 독립적인 A라는 조건이 있을 때 B라는 사건이 발생할 확률 -> 겹쳐서 (같이 연산해서) -> 특정한 범주형 변수들을 만족할 때, 정답값(예측값)이 나올 확률을 계산 -> 0.5? 크다 => 1\n",
        "* 모든 변수들이 독립적이고, 가능하면 범주형 (소속, 더미 변수화, 원핫인코딩...)\n",
        "* 자연어 분석 (딥러닝 전에 머신러닝을 통해서 구현하는 몇 안되는 자연어처리 방법 -> 어떤 특정 단어가 등장하느냐에 따라, 문장 또는 글의 주제/감정/속성 같은 것을 예측/분류하는 알고리즘 ex)스팸 여부, 리뷰 긍/부정 => 별점 1, 2, 3 => 범주형, 이상형의 다중분류 즉, 회귀가 안된다. 1.5 이런거 x)\n",
        "\n"
      ],
      "metadata": {
        "id": "DUpf0fOmxe9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 자연어 전처리"
      ],
      "metadata": {
        "id": "rl732rqa47Di"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 영어 기준\n",
        "* 문장 -> 단어가 등장 여부로 판단 (나이브 베이즈)\n",
        "* 단어 기준 -> 여백(스페이스) 기준으로 문장을 split\n",
        "1. 같은 단어인데 다른 단어로 인식되는 경우\n",
        "  * 특수문자(물음표, 마침표, 쉼표)\n",
        "  * 대소문자 다를 경우\n",
        "2. 의미는 없는데 구조상 들어있는 단어 (불용어 - stopwords)\n",
        "\n",
        "1. from string import puctuation -> 파이썬에서 제공하는 특수문자 묶음\n",
        "1. string.lower() -> 반복문, 리스트 컴프리헨션 -> 일괄적으로 소문자로\n",
        "1. nltk 에서 제공하는 불영어 리스트를 통해서 제거 \n",
        "> df.apply() => 해당 text 시리즈를 처리\n",
        "\n",
        "* from sklearn.feature_extraction.text import CounterVecdtorizer\n",
        "* 단어들 -> 벡터화 (컴퓨터가 이해할 수 있도록 배열)\n",
        "* 특정한 문장 묶음(corpus)에 등장하는 단어들을 '사전화' -> 단어 => 인덱스\n",
        "* 문장들을 => 어떤 단어가 어디서 몇번 등장했는지 배열로 변환\n",
        "\n",
        "* 한글의 경우. 단어의 어떠한 조사(은/는/이/가)가 붙었는지, 어떠한 용언 활용이 있는지에 따라서 단어의 표현이 달라지기 때문에 해당 단어의 '어근'을 찾아줘야함. 그것을 위해서 '형태소 분석기' => 갔다. 간다 (가다) => 가다 (Mecab, Okt, Khailll)\n"
      ],
      "metadata": {
        "id": "K90Iujgr49bE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 혼동 행렬 (confusion matrix)"
      ],
      "metadata": {
        "id": "XHlB_EOs60Yg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이진 분류 (참/거짓, 가설의 성립여부 등)\n",
        "* 정확도 중요하지만 틀렸을 때 어떠한 경향으로 틀렸는지 중요.\n",
        "  * ex) 코로나 검사를 한다 -> 결과(실제/결과 )- 결과 (양성-양성, 양성-음성, 음성-양성, 음성-음성)\n",
        "  * 실제로는 양성인데, 음성이 나오는경우 -> 위음성 (제2종 오류) -> 기준이 애매하여 놓침\n",
        "    > (임신을 해서) 배가 불러온 여성에게 임신이 아니라 판정\n",
        "\n",
        "    > 스팸인데 스팸이 아니라고 판정\n",
        "    \n",
        "    > 유죄인데 무죄 판결\n",
        "  * 실제로는 음성인데, 양성이 나오는경우 -> 위양성 (제1종 오류) -> 기준이 엄격하여 과잉\n",
        "    > 남성인데 임신이라고 판정\n",
        "    \n",
        "    > 스팸이 아닌데 스팸이라고 판정\n",
        "    \n",
        "    > 무죄인데 유죄라고 판결\n",
        "---\n",
        "* TN : True Negative (실제로도 거짓이고, 예측도 거짓)\n",
        "* TP : True Positive (실제로도 참, 예측도 참)\n",
        "* FP : False Positive (실제로는 거짓이고, 예측이 참, 제 1종 오류, 위양성)\n",
        "* FN : False Negative (실제로는 참이고, 예측이 거짓, 제2종 오류, 위음성)\n",
        "\n",
        "`from sklearn.metrics import confusion_matrix`"
      ],
      "metadata": {
        "id": "-NMmoQ0c63kQ"
      }
    }
  ]
}