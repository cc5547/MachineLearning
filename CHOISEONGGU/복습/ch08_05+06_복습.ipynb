{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CHOISEONGGU/MachineLearning_ChoiSG/blob/main/CHOISEONGGU/%EA%B3%B5%EB%B6%80%EC%9E%90%EB%A3%8C/ch08_05%2B06_%EB%B3%B5%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 결정 트리 (Decision Tree, 의사결정)\n",
        "* 트리 cf) 그래프 (자료구조)\n",
        "    * 한 방향으로 전개되는 데이터 구조\n",
        "    * 뿌리(root)에서 잎(leaf)로 뻗어가면서 데이터가 갈라지는 구조\n",
        "    * 뿌리 하나에 가지(잎)이 2개 -> 이진 트리\n",
        "* 결정 트리 -> 이진 트리 -> 기준점(지니 계수 -> 특정한 변수의 값을 기준을 나누었을 때 결과값이 얼마나 순수하게 나뉘냐) (0, 1) => 특정 변수로 나누면... (0 그룹) (1그룹)으로 안 나뉘어짐\n",
        "    * 키 기준으로 남/녀를 나누었을 때랑, 운동화를 신었냐 기준으로 남녀를 나뉘었을 때? 어디가 좀 더 깔끔하게 남/녀 구분?\n",
        "* 전제가 없음\n",
        "    * 데이터의 선형성, 독립변수들 간의 다중공산성(상관성), 데이터의 이상치 여부, 데이터 단위 -> 신경써주지 않아도 됨\n",
        "    * 나눠지는 기준값을 기준으로 그룹을 나눠서 대응 -> 선형을 이루던가, 거리를 재던가 하지 않음, 그냥 반반 혹은 의미는 규모의 그룹으로 나누기\n",
        "    * 딥러닝을 제외한 머신러닝 쪽에서 가장 높은 예측력을 보이는 알고리즘 계열 -> 점점 고도화됨 -> 가장 기초적인 결정 트리 -> 경사하강법, 앙상블, 배깅, 부스팅 같은 기타 추가적인 기법들을 도입한 고도화된 트리 모델\n",
        "* 종속변수가 이산형이든 연속형이든 상관 없음, 분류문제/회귀문제 모두 대응 가능 (`classifier, regressor`)\n",
        "* 이걸 이해해야 뒤에 나오는 고도화된 트리 모델들의 기초 원리가 이해 가능\n",
        "* 가장 단순한 트리 모델이기 때문에, 시각화나 설명이 간단 (`plot_tree`)\n",
        "    * 예측력( 결과, 평가, 점수) vs 설명력 (시각화, 원인, 영향도) -> 자율주행 vs 내비게이션"
      ],
      "metadata": {
        "id": "Ja5UkUCr85K6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 범주형 변수의 변환 -> 피쳐 엔지니어링적 성격\n",
        "* 순서형 : 크고 작음이 존재한다(등급) -> A+같은 학점, 신용등급\n",
        "  * 트리계열 -> 라벨 인코딩 -> n개를 그냥 1~n까지로 인코딩해도 됨.\n",
        "  * 범주형 변수 -> 거기에 대응하는 대표적인 값을 넣어서 순서형으로 사용할 수 있다.\n",
        "    * 나라 -> 나라별 고소득자 비율\n",
        "    * 브랜드 -> 브랜드 평퍈, 해당 기업의 시가총액( 'groupby, merge' )\n",
        "    * 이렇게 변환해줄 경우에는 가능하면 안 겹치는 값을 사용해야한다.\n",
        "    * 통계or대표값을 잘못 적용해주면? 이상한 모델링이 되어버린다.\n",
        "* 명목형 : 위아래 없음 / 소속, 특성, 상태\n",
        "  * 더미변수로 해준다.(dummies)\n",
        "---\n",
        "* 더미변수화를 하면, 해당 범주 종류(고윳값)의 n-1개의 행의 행이 생김.( = n-2개로 늘어남) -> 열이 늘어나는 건, 행당 처리해야하는 데이터가 늘어남 -> 빅데이터(몇만, 몇십백만...) 배수로 늘어남 -> 100개의 종류가 있는 데이터 -> 더미변수화?하게되면 -> 모델 학습 효율이 떨어짐 -> 모델 성능의 문제, 효율"
      ],
      "metadata": {
        "id": "El7cG-DTAabe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 결정 트리의 하이퍼 패러미터 튜닝\n",
        "* max_depth : 최대 노드의 깊이\n",
        "  *노드 : 얼마나 밑으로 많이 전개되었는가?(최대)\n",
        "  * 'from sklearn.tree import Decisioin...' -> default? : 확실히 두 그룹으로 나뉠 때까지\n",
        "  * 과최적화(오버피팅, over-fitting) : 훈련셋 데이터에 심하게 맞춰져 있어서, 새로운 데이터(검증셋, 시험셋)을 만났을 때 제대로 분류하지 못한다.\n",
        "  * 과소학습(언터피팅, under-fitting) : 학습이 제대로 안된 것.\n",
        "  * 과유불급이라하지만 이 학습에서는 비교적 차라리 과한게 더 낫다.\n",
        "  * 일정 이상 단계로 노드 전개(깊어지는 것)을 막아서, 너무 세세한 구분 조건을 주지 않게 함"
      ],
      "metadata": {
        "id": "a-HaM_5CDZSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 랜덤 포레스트 (Random Forest)\n",
        "* 결정 트리 -> 과최적화가 잘 일어남 -> 해결하기 위해서 `앙상블(ensemble)`이 나옴 -> 백짓장도 맞들면 낫다.같은 느낌 -> 여러 모델들을 통합시켜서 더 좋은 예측력을 보일 수 있게 하는 모델.\n",
        "* 트리 -> 포레스트 -> 트리를 여러개 생성하고, 결과값들을 투표 (분류 -> 모델1 :0, 모델2 :0, 모델3: 1 => 0)나 평균화 시켜서 예측력 높임\n",
        "* 이거 제외하곤, 속도가 조금 느려진다( 모델을 여러개 만들기 때문에) 제외하곤 결정 트리하곤 유사. -> 여러개를 섞기 때문에 시각화가 안된다."
      ],
      "metadata": {
        "id": "Ryr3t_CTFZXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단위 처리 & 도메인 지식을 이용한 전처리( 피쳐 엔지니어링)\n",
        "* 단위를 만나게 됨 -> cc, kg, N -> 숫자로 주어지는 것이 아니라, 단위와 함께(같은 열 or 다른 열 일수도 있지만) 주어지는 경우가 많다.\n",
        "1. 값과 단위를 분리한다(value, unit) -> `series.str.split()`,`series.str.splite(expand=True)`, `series.str.extract(정규표현식)`, `series.apply(함수)`\n",
        "2. 단위가 한 가지 인가?\n",
        "  1. 단위가 한가지면 ( cc, m 등으로 통일) -> 그 값 자체를 써주면 됨.\n",
        "  2. 단위가 두 가지 이상이면?\n",
        "    * 한쪽 값으로 통일해주던가(Nm, Kgm-> 변환공식이 존재할 경우)\n",
        "    * 가격, 석차, 비율...-> 공통적? ex) 연료에 따른 연비를 -> 가격에 따른 연비로 바꿔줌\n",
        "    * 도메인 지식 -> 특정 영역에 대해서 가지고 있는 상식, 기술적 지식, 등등"
      ],
      "metadata": {
        "id": "x5XyAxe9Gq3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Ford\n",
        "* k 가 등장한 것은? : 설정해주는 k값, k-fold는 데이터를 k 구간만큼 나눠서 해당 1~k번째(0~k-1번째), 순서대로 시험셋으로 사용해줘서 `train_test_split`의 한계를 부숴준다. -> 모델의 신뢰성, 평가에 있어서 정확도를 높인다.\n",
        "* 시간이 오래 걸린다(if k=5이면 5등분해서 5번 모델을 돌려야하고 + 하이퍼패러미터 튜닝)까지 하게되면 러닝타임이 오래거린다."
      ],
      "metadata": {
        "id": "9V53y4yEI1yg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 랜덤 포레스트의 하이퍼 패러미터 튜닝\n",
        "* `n.estimators` => 숲을 몇 개의 트리로 구성할 거임?\n",
        "---\n",
        "\n",
        "* 트리 기반에서의 하이퍼 패러미터 튜닝은 주로 과소/과대적합을 방지하기 위해 사용한다.\n",
        "* max_depth\n",
        "* `min_samples_split` : 데이터를 두 그룹으로 나눠줄 때, 이 숫자보다 적으면 더이상 이진트리를 만들지 않겠다. 노드 생성을 끝낸다.\n",
        "* `min_samples_leaf` \n",
        "\n",
        "* split -> 나누어 진 다음에 생각해서 stop\n",
        "* leaf -> 나누기 전에 생각해서 \n",
        "\n",
        "_chatGPT's answer_<br>\n",
        "리프 노드가 되기 위한 최소 샘플 수를 지정하는 매개변수입니다. 이 매개변수는 리프 노드가 될 수 있는 샘플 수가 min_samples_leaf보다 작아지면 노드 분할을 멈추도록 합니다. 즉, 리프 노드가 될 수 있는 샘플 수가 min_samples_leaf보다 적다면 해당 노드는 분할을 멈추고 리프 노드가 됩니다. 이 값을 너무 낮게 설정하면 모델이 과적합되기 쉽고, 너무 높게 설정하면 모델이 너무 단순해져서 과소적합될 가능성이 높아집니다.\n",
        "\n",
        "차이점은 min_samples_split은 노드를 분할할 때 고려해야 할 최소 샘플 수를 설정하는 것이고, min_samples_leaf는 리프 노드가 되기 위한 최소 샘플 수를 설정하는 것입니다. min_samples_split은 노드 분할에 직접적으로 영향을 주며, min_samples_leaf는 리프 노드가 되기 위한 샘플 수를 조절하여 모델의 복잡도를 조절합니다. 따라서 두 매개변수 모두 모델의 복잡도를 조절하여 과적합과 과소적합을 방지하는 데 중요한 역할을 합니다."
      ],
      "metadata": {
        "id": "dmMffs2FJeq4"
      }
    }
  ]
}