{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXoWBFd+dsgRL+KNZQM+PK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaiwon880/MachineLearning_jw/blob/main/jaiwon880/CH08_03%2B04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN(K-Nearest Neighbor)"
      ],
      "metadata": {
        "id": "vYnTiJeWqPU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 거리 기반 -> 열들(관측값, 독립변수, 피쳐) 거리를 재서, 그 거리들 간의 계산을 해서 특정한 정답값(종속변수, 예측값, 라벨)들이 뭉쳐있는지 확인하고, 해당 정답값들과 얼마나 가까운지 바탕으로 새로운 예측값\n",
        "* 선형 관계 성립 X <-> 선형회귀, 로지스틱회귀(분류)\n",
        "  * 선형 관계 : x => 증감함에 따라 y라는 값이 일관적이게 증가, 감소하는관계\n",
        "(비례/반비례) => 일관된 직선으로 (독립변수들)-(종속변수) 간의 관계가 나타나는 것 (수학 공식 => 1차식,)\n",
        "* 단위 문제 -> 단위가 정리가 안 되면, 특정한 변수의 단위 크기에 따른 영향이 극대화 혹은 극소화\n",
        "  * 스케일링\n",
        "* 이상치 (일반적으로 통계적으로 예측되는 최대/최소값 / 일반적으로 상관관계에 벗어나는 값들)\n",
        "* 분류(Classifier)/회귀(Regressor)\n",
        "* 로지스틱 회귀 (분류) -> 이진 분류 (0,1, True, False)\n",
        "* KNN -> 다중분류(2개부터 N개 까지...)\n",
        "* 데이터가 늘어나면 속도가 느려짐\n",
        "* K라는게 \"K개\"를 선택해야함 -> 적절한 K를 선택해 줘야함 (k=5, default)"
      ],
      "metadata": {
        "id": "-lCWdzNRqWx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 스케일링"
      ],
      "metadata": {
        "id": "bsdtciQqtRYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 단위가 중요한 경우 (거리 기반) -> 단위를 맞춰주기 위해 통계쩍인 변환을 시켜주는 전처리\n",
        "* 표준화 스케일링\n",
        "  * 표준 정규분포로 만들어주는 스케일링\n",
        "  * 표준 정규분포 -> 평균이 0이고, 표준편차가 1인 정규분포(자연적으로 발생하는 일반적인 확률분포)\n",
        "  * 일반적으로 통계에 쓰이는 비교를 위한 표준\n",
        "  * 원본의 모양을 포기하고 대신에 다양한 변수들 간의 비교를 위해\n",
        "  * 이상치 영향 여부: `0` 이상치가 발생하면 평균에 영향을 줌\n",
        "  * 분포 모양 변화: `0`\n",
        "* 로버스트 스케일링\n",
        "  * 1사분위, 2사분위, 3사분위수를 써서 양극단의 이상치에 대한 영향을 최소화한 '굳건한' 스케일링\n",
        "  * 모든 값 - 2사분위 수(중간값, 중위 값) / (3 사분위수 - 1 사분위수)\n",
        "  * '평균'을 안쓴다 -> 양극단 이상치 영향이 없어짐\n",
        "  * 분포 모양이 스케일링을 하면 양방향으로 퍼지게 되는데 (1분위~3분위 값들을 잘 스케일링이 되는데, 나머지 값들은 좀 버려지는 경향)\n",
        "  * 이상치 영향 여부: X\n",
        "  * 분포 모양 변화: 1~3사분위 괜춘... 양극단에 가까운 값들은...ㅠ\n",
        "* 최대최소 스케일링\n",
        "  * 최대값과 최솟값을 사용해서 단위만 0~1 사이로 만듦\n",
        "  * (모든 값 - 최소값) / (최대값 - 최소값) (최소값은 0, 최대값 1인 분포)\n",
        "  * 모양은 잘 보정이 되는데... 이상치는 그대로\n",
        "  * 이상치 영향 여부: `0`\n",
        "  * 분포 모양 변화: `X`\n",
        "\n",
        "\n",
        "* `sklearn.preprocessing`\n"
      ],
      "metadata": {
        "id": "Rd6UfQ7CtSyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 나이브 베이즈"
      ],
      "metadata": {
        "id": "NvoFIqNExcID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 베이즈 정리 (조건부 확률을 기반한) 알고리즘\n",
        "* 특정한 독립적인 A라는 조건이 있을 때 B라는 사건이 발생할 확률 -> 겹쳐서 (같이 연산해서) -> 특정한 범주형 변수들이 만족할 때, 정답값(예측값)이 나올 확률을 계산 -> 0.5? 크다 => 1\n",
        "* 모든 변수들이 독립적이고 가능하면 범주형, (소속, 더미 변수화, 원핫인코딩...)\n",
        "* 자연어 분석 (딥러닝 전에 머신러닝을 통해 구현하는 몇 안 되는 자연어 처리 방법 -> 어떠한 특정 단어가 등장하느냐에 따라 문장, 또는 글의 주제/감정/속성 같은 것을 예측/분류하는 알고리즘 (스팸 여부, 리뷰 긍/부정)\n",
        "=> 별점1, 별점2, 별점3...\n",
        "=> 범주형, 이산형 다중분류"
      ],
      "metadata": {
        "id": "P8ZoqE6pxfB4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 자연어 전처리"
      ],
      "metadata": {
        "id": "Wxf-G93z5IeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 영어 기준\n",
        "* 문장 -> 단어가 등장 여부로 판단 (나이브 베이즈)\n",
        "* 단어 기준 -> 여백(스페이스) 기준으로 문장을 split\n",
        "1. 같은 단어인데도, 다른 단어로 인식되는 경우\n",
        "  * 특수 문자(물음표, 마침표, 쉼표)\n",
        "  * 대소문자 다를 경우\n",
        "2. 의미는 없는데 구조상 들어있는 단어(불용어 - stopwords)\n",
        "\n",
        "\n",
        "1. `from string import punctuation` -> 파이썬에서 제공하는 특수문자 묶음\n",
        "1. `string.lower()` (반복문, 리스트 컴프리헨션) -> 일괄적으로 소문자로\n",
        "1. `nltk`에서 제공하는 불용어 리스트를 통해 제거\n",
        "\n",
        "> 함수화해서 df.apply() => 해당 text 시리즈를 처리\n",
        "\n",
        "* `from sklearn.feature_extraction.text import CounterVectorizer`\n",
        "* 단어들 -> 벡터화 (컴퓨터가 이해할 수 있도록 배열화)\n",
        "* 특정한 문장 묶음(corpus)에 등장하는 단어들을 '사전화' -> 단어=>인덱스\n",
        "* 문장들을 -> 어떤 단어가 어디서 몇 번 등장했는지\n",
        "\n",
        "* 한글의 경우? 단어의 어떠한 조사(은/는/이/가)가 붙었는지, 어떠한 용언 활용이 있는지에 따라서 단어의 표현이 달라지기 때문에 해당 단어의 '어근'을 찾아줘야 함.\n",
        "그것을 위해 '형태소 분석기' => 갔다, 간다, (가다) => 가다(Wecab, Okt, Khailll)"
      ],
      "metadata": {
        "id": "R3xY9wxd5KBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 혼동 행렬 (confusion metrix)"
      ],
      "metadata": {
        "id": "VPsDhhTH6y6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이진 분류(참/거짓, 가설의 성립여부 등)\n",
        "* 정확도도 중요하지만 (맞추냐 자체도 중요) 틀렸을 때 어떠한 경향으로 틀리냐도 중요\n",
        "* 코로나 검사를 한다 -> 결과 (양성(실제)-양성, 양성-음성, 음성-양성, 음성-음성)\n",
        "* 실제로는 양성인데, 음성이 나오는 경우? -> 위음성(제 2종 오류) -> 놓친 것 -> 기준이 느슨한 것\n",
        "  * (임신을 해서) 배가 불러온 여성에게 임신이 아니라고 판정\n",
        "  * 스팸인데 스팸이 아니라고 판정\n",
        "  * 유죄인데 무죄라고 놓아줌\n",
        "* 실제로는 음성인데, 양성이 나오는 경우? -> 위양성 (제 1종 오류) -> 과잉으로 잡은 것 -> 기준이 엄격한 것\n",
        "  * 남성인데 임신이라고 판정\n",
        "  * 스팸이 아닌데 스팸이라고 판정\n",
        "  * 무죄인데 유죄라고 잡아감\n",
        "\n",
        "\n",
        "---\n",
        "TN: True Negative (실제로도 거짓이고, 예측도 거짓임)\n",
        "TP: True Positive (실제로도 참이고, 예측도 참임)\n",
        "FN: False Negative ((실제로는 참인데 예측이 거짓임, 제2종 오류, 위음성)\n",
        "FP: False Positive (실제로는 거짓인데, 예측이 참임, 제1종 오류, 위양성)\n",
        "\n",
        "\n",
        "`from sklearn.metrics import confusion_matrix`"
      ],
      "metadata": {
        "id": "YtIVzpab64Yi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "788VXLK1o-rZ"
      },
      "outputs": [],
      "source": [
        ")import numpy as np\n",
        "import pandas as pd\n",
        "from "
      ]
    }
  ]
}