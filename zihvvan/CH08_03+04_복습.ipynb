{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zihvvan/MachineLearning/blob/main/zihvvan/CH08_03%2B04_%EB%B3%B5%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN (K-Nearest Neighbor)"
      ],
      "metadata": {
        "id": "SDFNaMciqSml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 거리 기반 -> 열들(관측값, 독립변수, 피쳐) 거리를 재서, 그 거리들 간의 계산을 해서, 특정한 정답값(종속변수, 예측값, 라벨)들이 뭉쳐있는지를 확인하고, 해당 정답값들과 얼마나 가까운지를 바탕으로 새로운 예측값\n",
        "* 선형 관계 성립 X <-> 선형회귀(회귀), 로지스틱회귀(분류) => 선형관계\n",
        "    * 선형 관계 : x => 증감함에 따라 y라는 값이 일관적이게 증가, 감소하는 관계 (비례/반비례) => 일관된 직선으로 (독립변수들)-(종속변수) 간의 관계가 나타나는 것 (수학 공식 => 1차식.)\n",
        "* 단위 문제 -> 단위가 정리가 안되면, 특정한 변수의 단위 크기에 따른 영향이 극대화 혹은 극소화.\n",
        "    * 스케일링\n",
        "* 이상치 (일반적으로 통계적으로 예측되는 최대/최소값. / 일반적으로 상관관계에 벗어나는 값들)\n",
        "* 분류(Classifier)/회귀(Regressor)\n",
        "* 로지스틱 회귀 (분류) -> 이진분류 (0,1 True, False)\n",
        "* KNN -> 다중분류 (2개부터 N개까지...)\n",
        "\n",
        "* 데이터가 늘어나면 속도가 느려짐 (거리를 다 재야하니까)\n",
        "* K라는게 'K개'를 선택해야함 -> 적절한 K를 선택해줘야함 (k=5, default)"
      ],
      "metadata": {
        "id": "lYhjJ8bPqWWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 스케일링"
      ],
      "metadata": {
        "id": "E_Cww3OBwlbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 단위(Scale)가 중요한 경우 (거리 기반) -> 단위를 맞춰주기 위해서 통계적인 변환을 시켜주는 전처리 (Scaling)\n",
        "* 표준화 스케일링\n",
        "    * 표준정규분포로 만들어주는 스케일링\n",
        "    * 표준정규분포 -> 평균이 0이고, 표준편차 1인 정규분포 -> 정규분포 : 자연적으로 발생하는 일반적인 확률분포 (종모양 분포) -> **전체 값에서 평균을 빼고 표준편차로 나눠주면** -> 평균이 0이고 표준편차 1\n",
        "    * 일반적으로 통계에 쓰이는 비교를 위한 표준\n",
        "    * 원본의 모양을 포기를 하고, 대신에 다양한 변수들 간의 비교를 위해.\n",
        "    * 이상치 영향 여부 : `O` (이상치가 발생하면 평균에 영향을 주는데...)\n",
        "    * 분포 모양 변화 : `O'\n",
        "* 로버스트 스케일링 (Robust)\n",
        "    * 1사분위, 2사분위, 3사분위수를 써서 양극단의 이상치에 대한 영향을 최소화한 '굳건한' 스케일링\n",
        "    * (모든 값 - 2사분위수(중간값, 중위값)) / (3사분위수 - 1사분위수)\n",
        "    * '평균'을 안쓴다 -> 양극단 이상치 영향이 없어짐\n",
        "    * 분포 모양이 스케일링을 하면 좀 양방향으로 퍼지게 되는데... (1분위~3분위 값들은 잘 스케일링이 되는데, 나머지 값들은 좀 버려지는 경향...)\n",
        "    * 이상치 영향 여부 : `X`\n",
        "    * 분포 모양 변화 : 1~3사분위 괜춘... 양극단에 가까운 값들은... ㅠㅠ\n",
        "* 최대최소 스케일링\n",
        "    * 최대값과 최소값을 사용해서 단위만 0~1 사이로 만듦\n",
        "    * (모든 값 - 최소값) / (최대값 - 최소값) (최소값은 0, 최대값 1인 분포)\n",
        "    * 모양은 잘 보정이 되는데... 이상치는 그대로.\n",
        "    * 이상치 영향 여부 : `O`\n",
        "    * 분포 모양 변화 : `X`\n",
        "\n",
        "* `sklearn.preprocessing`"
      ],
      "metadata": {
        "id": "VU70YQimwlUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 나이브 베이즈"
      ],
      "metadata": {
        "id": "J-1L12iOxnra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 베이즈 정리 (조건부 확률을 기반한) 알고리즘\n",
        "* 특정한 독립적인 A라는 조건이 있을 때 B라는 사건이 발생할 확률 -> 겹쳐서 (같이 연산해서) -> 특정한 범주형 변수들을 만족할 때, 정답값(예측값)이 나올 확률을 계산 -> 0.5? 크다 => 1\n",
        "* 모든 변수들이 독립적이고, 가능하면 범주형. (소속. 더미 변수화, 원핫인코딩...)\n",
        "* 자연어 분석 (딥러닝 전에 머신러닝을 통해서 구현하는 몇 안되는 자연어처리 방법 -> 어떠한 특정 단어가 등장하느냐에 따라, 문장 또는 글의 주제/감정/속성 같을 것을 예측/분류하는 알고리즘 (스팸 여부, 리뷰 긍/부정) => 별점1, 별점2, 별점3... => 범주형, 이산형의 다중분류\n"
      ],
      "metadata": {
        "id": "EF8zF_M2xplx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 자연어 전처리"
      ],
      "metadata": {
        "id": "SHvv5YeF7lUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 영어 기준\n",
        "* 문장 -> 단어가 등장 여부로 판단 (나이브 베이즈)\n",
        "* 단어 기준 -> 여백(스페이스) 기준으로 문장을 split.\n",
        "1. 같은 단어인데도, 다른 단어로 인식되는 경우?\n",
        "    * 특수문자(물음표, 마침표, 쉼표)\n",
        "    * 대소문자 다를 경우\n",
        "2. 의미는 없는데 구조상 들어있는 단어 (불용어-stopwords)\n",
        "\n",
        "1. `from string import punctuation` -> 파이썬에서 제공하는 특수문자 묶음\n",
        "1. `string.lower()` (반복문, 리스트 컴프리헨션) -> 일괄적으로 소문자로\n",
        "1. `nltk`에서 제공하는 불용어 리스트를 통해서 제거\n",
        "\n",
        "> 함수화해서 df.apply() => 해당 text 시리즈를 처리\n",
        "\n",
        "* `from sklearn.feature_extraction.text import CounterVectorizer`\n",
        "* 단어들 -> 벡터화 (컴퓨터가 이해할 수 있도록 배열화)\n",
        "* 특정한 문장 묶음(corpus)에 등장하는 단어들을 '사전화' -> 단어=>인덱스\n",
        "* 문장들을 => 어떤 단어가 어디서 몇번등장했는지 => 배열로 변환\n",
        "\n",
        "* 한글의 경우? 단어의 어떠한 조사(은/는/이/가)가 붙었는지, 어떠한 용언 활용이 있는지에 따라서 단어의 표현이 달라지기 때문에 해당 단어의 '어근'을 찾아줘야함. 그것을 위해서 '형태소 분석기' => 갔다, 간다 (가다) => 가다 (Mecab, Okt, KhaiIII)"
      ],
      "metadata": {
        "id": "2On-SY1R7mHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 혼동 행렬 (confusion matrix)"
      ],
      "metadata": {
        "id": "TVXlRzIV7qQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이진분류 (참/거짓, 가설의 성립여부 등)\n",
        "* 정확도 중요하지만 (맞추냐 자체도 중요) 틀렸을 때 어떠한 경향으로 틀리냐도 중요\n",
        "* 코로나 검사를 한다 -> 결과 (양성(실제)-양성(결과), 양성-음성, 음성-양성, 음성-음성)\n",
        "* 실제로는 양성인데, 음성이 나오는경우? -> 위음성 (제2종 오류) -> 놓친 것 -> 기준이 느슨한 것\n",
        "    * (임신을 해서) 배가 불러온 여성에게 임신이 아니라 판정\n",
        "    * 스팸인데 스팸이 아니라고 판정\n",
        "    * 유죄인데 무죄라고 놓아줌\n",
        "* 실제로는 음성인데, 양성이 나오는경우? -> 위양성 (제1종 오류) -> 과잉으로 잡은 것 -> 기준으로 엄격한 것\n",
        "    * 남성인데 임신이라고 판정\n",
        "    * 스팸이 아닌데 스팸이라고 판정\n",
        "    * 무죄인데 유죄라고 잡아가둠\n",
        "---\n",
        "* TN : True Negative (실제로도 거짓이고, 예측도 거짓임)\n",
        "* TP : True Positive (실제로도 참이고, 예측도 참임)\n",
        "* FP : False Positive (실제로는 거짓인데, 예측이 참임, 제1종 오류, 위양성)\n",
        "* FN : False Negative (실제로는 참인데, 예측이 거짓임, 제2종 오류, 위음성)\n",
        "\n",
        "`from sklearn.metrics import confusion_matrix`"
      ],
      "metadata": {
        "id": "j5K0JxzG7rw8"
      }
    }
  ]
}