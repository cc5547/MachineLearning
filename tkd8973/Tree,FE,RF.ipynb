{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tkd8973/MachineLearning_SW/blob/main/tkd8973/Tree%2CFE%2CRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree(결정 트리)\n",
        "* 트리 cf) 그래프(자료구조)\n",
        ">* 한 방향으로 전개되는 데이터 구조\n",
        ">* 뿌리(root) 에서 잎(leaf) 으로 뻗어가면서 데이터가 갈라지는 구조\n",
        "* 결정트리-> 이진트리 -> 기준점(지니계수) -> 특정한 변수의 값으로 기준을 나누었을 때,결과값이 얼마나 순수한지(0,1) -> 특정 변수로 나누면 (0 그룹) (1 그룹) 으로 안 나누어 진다.\n",
        "* ex)키 기준으로 남/녀 를 구분하는 것 과, 운동화 착용 여부 기준으로 남/녀를 구분하는 것 중에 어느게 더 깔끔하게 구분하는가?\n",
        "* 전제가 없음\n",
        ">* 선형성, 독립변수들의 상관성, 이상치 여부, 데이터 단위 신경X\n",
        ">* 나눠지는 기준값을 기준으로 그룹을 나눠서 대응 -> 선형, 거리X, 반반 혹은 의미있는 규모의 그룹으로 나눔\n",
        ">* DL을 제외한 ML에서는 가장 높은 예측력을 보이는 알고리즘 -> 점점 고도화 -> 가장 기초적인 트리 -> 경사하강법, 앙상블, 배깅, 부스팅 같은 추가적인 기법들을 도잏반 고도화된 트리 모델\n",
        "* 종속 변수가 이산, 연속 전부 상관X, 분류(Classifier)/회귀(Regression) 전부 가능\n",
        "* 결정트리를 이해해야 고도화된 트리 모델의 기초 원리를 이해 할 수 있음\n",
        "* 가장 단순한 트리모델로, 시각화나 설명이 제일 간단(`plot_tree')\n",
        ">* 예측력(결과, 평가, 점수) vs 설명력(시각화, 원인, 영향도) : 자율주행(예측), 내비게이션(설명)\n",
        "\n",
        "* BaseLine 모델 설정, 해석과 다른 알고리즘 사용"
      ],
      "metadata": {
        "id": "ZCQ0aqmDv7Zm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 범주형 변수의 변환 -> 피쳐 엔지니어링\n",
        "* 순서형 : 크고 작음이 있다 : A+ > B , AAA>BBB\n",
        ">* 트리 계열 -> 라벨 인코딩 -> n개를 그냥 1~n으로 인코딩O\n",
        ">* 범주형 변수 -> 대응하는 대표적인 값을 넣어서 순서형으로\n",
        ">>* 나라-> 나라별 고소득자 비율, 브랜드 -> 브랜드 평판, 해당 기업의 시가총액\n",
        ">>* 이렇게 변화할 경우, 가능하면 겹치지 않는 값 으로\n",
        ">>* 대표값을 잘못 지정하면 모델링이 이상함\n",
        "\n",
        "* 명목형 : 소속, 특성, 상태\n",
        ">* 더미변수로 \n",
        "---\n",
        "* 더미변수를 진행시, 해당 범주의 고윳값 개수-1 개의 열이 생김 -> 열이 생긴다는건, 처리할 데이터가 증가 -> 효율,성능 저하 \n",
        ">*ex) 100개의 고유값 -> 더미 -> 학습 효율 감소 -> 모델 성능의 문제, 효율\n"
      ],
      "metadata": {
        "id": "esfTyQsLAGMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 결정 트리의 하이퍼 파라미터 튜닝\n",
        "* max_depth : 노드를 전개할 깊이\n",
        ">* `from sklearn.tree import DicisionTree` -> default : \n",
        ">* 과최적화(Over-Fitting) : TrainSet에 과적합 되어 새로운 데이터(TestSet,  New Data)를 만나면 제대로 분류 못함\n",
        ">* 과소학습(Under-Fitting) : 망함, 학습이 제대로 이루어 지지 않은 것\n",
        ">* 노드의 전개를 일정 단계 이상으로 가는 것을 막아 너무 세세한 구분 조건을 주지 않게 함\n"
      ],
      "metadata": {
        "id": "Sq9g0UY1DZLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest\n",
        "* 결정 트리 -> 과최적화(Over-Fitting) -> 앙상블(ensemble) -> 여러 모델을 통합시켜 더 좋은 예측력을 보일 수 있게 하는 모델\n",
        "* 트리 -> 포레스트 ; 트리를 여러개 생성하고, 결과값을 투표 (분류 - 모델 1:0, 모델 2:1, 모델3:2)나 평균화 시켜 예측력을 높임\n",
        "* 모델을 여러개 생성하기 때문에 속도가 느리고, 시각화 불가능 "
      ],
      "metadata": {
        "id": "xlUcM84TFZ8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리 (단위 & 도메인 지식을 이용한 피쳐엔지니어링)\n",
        "* 단위 -> CC,KGm,Nm(NM) -> 숫자로 주어지지 않고 단위와 함께 주어지는 경우가 많음\n",
        "1. 값과 단위를 분류 `series.str.split()`,`series.str.split(expand=True)`,`series.str.extrace(정규표현식)`, `series.apply(함수)` ex)100 CC -> [100,CC] \n",
        "2. 단위가 한가지 일 경우\n",
        ">* 단위가 한가지(cc, m, km 등) 이면 그값 자체를 사용\n",
        "3. 단위가 두가지 이상 일 경우\n",
        ">* 한쪽값으로 통일 (m->km 같이 변환이 가능할경우)\n",
        ">* 가격, 석차, 비율 -> 공통적? ex) 연료/연비 -> 가격/연비\n",
        "\n",
        "* 도메인 지식 : 특정 영역에 대해 가지고 있는 상식, 기술적 지식"
      ],
      "metadata": {
        "id": "0dNNVX_xGpwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Fold\n",
        "* K-Fold : 데이터를 K구간만큼 나눠서 1~K번쨰 까지 나눠 순서대로 TestSet을 사용하여 모델의 신뢰성, 평가에 있어서 정확도를 높일 수 있음\n",
        "* 모델을 여러번 돌리기 때문에 시간이 오래 걸림"
      ],
      "metadata": {
        "id": "aawe1kKUI2Qk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest의 하이퍼 파라미터\n",
        "* n_estimator : 숲을 몇개의 트리로 구성할 것 인가\n",
        "* max_depth\n",
        ">* `min_samples_split` : 데이터를 두 그룹으로 나눌 때, 이 숫자보다 적으면 더이상 트리를 만들지 않음\n",
        ">* `min_samples_leaf` : 리프 노드가 되 위한 최소 샘플 수를 지정하는 매개변수, 샘플 수가 `min_samples_leaf` 보다 작아지면 노드 분할을 멈춤 값을 낮추면 오버피팅, 높게 설정하면 과소적합"
      ],
      "metadata": {
        "id": "4D_2eyWSJiHl"
      }
    }
  ]
}